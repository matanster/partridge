% Outline Project Specification Report

%The document is a report
\documentclass[12pt,a4paper]{article}

%define horizontal rule
\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}

\usepackage{fullpage}

%use the listings package
\usepackage{listings}
%use the English language
\usepackage[english]{babel}
%use graphics
\usepackage{graphicx}
%use wrap figures
\usepackage{wrapfig}
%geometry stuffs
\usepackage{lscape}
%use natbib bibliography package
%\usepackage[numbers]{natbib}
%use harvard bibliography package
%\usepackage{harvard}	
%use captions
\usepackage{caption}
%use multi-row tables
\usepackage{multirow}
\usepackage{url}
\usepackage{subcaption}

\begin{document}

%use harvard citations
%\citationstyle{agsm}

%include the title page
\input{revision}
\input{title}

%some definitions for paragraph layout stuff
\setlength{\parindent}{0pt}
\setlength{\parskip}{1.5ex plus 0.5ex minus 0.2ex}

\tableofcontents

\pagebreak

\section{Project Summary}

Partridge is a web-based tool designed to assist in information processing and knowledge
acquisition within the domain of scientific research.

Since the advent of the 'Digital Age' and the ability of computers to copy and
reproduce information for a negligible cost, the amount of information
available to researchers has been increasing drastically.  B-C Bj\"{o}rk (2009)
estimates that approximately 1.4 Million papers were published in the year 2006
alone\cite{bjork2009}. Moreover, the growing popularity of Open Access
publishing (making papers available for free online\cite{Suber2012}) across
most scientific disciplines\cite{bjork2009}\cite{harnad2004comparing} is
providing researchers with an even larger volume of information to be
processed. As available information increases, relevant material becomes
progressively more difficult to find and the need for an automated information
retrieval tool more apparent. The problem is even more vital for General
Practitioners. Goldacre (2008:97) points out that ``there have been an
estimated 15 million medical academic articles published so far, and 5000
journals published every month... picking out what's relevant is a garganutan
task."\cite{goldacre2009bad} 

Partridge aims to autonomously process as many scientific papers as possible to
facilitate researchers who would otherwise be required to manually read each
paper themselves. This should reduce the amount of information that the reader
is required to process themselves, thereby speeding up the research process.
Partridge will achieve this through the use of several existing techniques in
Natural Language Processing which are discussed below.

From the point of view of it's users, Partridge will assist researchers in two
ways. The system will provide filtering of papers based upon their
specific domain (i.e. is the paper primarily concerned with methodology within
an experiment in chemistry or is it about Ethics in Psychological studies?) and
their result, whether the paper yielded positive, negative or inconclusive
evidence for a hypothesis. Depending upon the time constraints of the
project, it is hoped that Partridge will also offer a user 'profiling' system
that provides recommendations for researchers based on their reading history.
This feature should help users find relevant papers more quickly or find
research that they may have otherwise overlooked.

There are already several tools that help researchers manage the vast library
of journals available on the internet. Search engines such as Google
({\url{http://www.google.com/}}), and social citation management tools such as
CiteULike ({\url{http://www.citeulike.org}}), do offer some assistance in
tracking down relevant information. However, these tools are often too general
or rely upon the user knowing exactly what keywords to use before carrying out
the search. These drawbacks are further discussed in Section
\ref{sec:prior_art} below.

To overcome the drawbacks of these existing systems, Partridge will make use of
several cutting edge Artificial Intelligence (AI) techniques in order to analyse and
process the papers in a more in depth way. AI is a very complex and field and
implementing the above features will be incredibly challenging. To help with
this, Partridge will build upon the system implemented by Liakata et al. for
classifying papers on a sentence-by-sentence basis\cite{citeulike:10444769} and
make use of Natural Language Toolkit for Python
\cite{Bird:2006:NNL:1225403.1225421} 

\section{Current Progress}

The Partridge project has been underway since the beginning of October. The
following section looks at some literature on the subjects of Natural Language
Processing and information retrieval within the domain of scientific papers.
Some related works are investigated and compared to Partridge and details of
prototyping work that has been carried out are given.

\subsection{Literature Review}

In science fiction literature and films, Artificial Intelligence (AI) and the
ability of machines to automatically process and understand human language is
almost always present. The current state of AI is a long way behind these
fantastic visions. Dale(2000) comments that ``Even the most ardent exponent of
artificial intelligence research would have to admit that the likes of HAL in
Kubrick's 2001: A Space Odyssey remain firmly in the realms of science
fiction\cite{dale2000handbook}".

Despite lacking behind the imagination of authors and script writers, over the last 60 years there
has been a huge amount of progress in AI techniques. The phrase `Artificial
Intelligence' was coined in 1956\cite{russell2010artificial} and can be used as
an umbrella term, describing many subfields from ``learning and perception
to... diagnosing diseases\it{(Ibid)}."

Turing(1950) proposed a test for determining whether a machine could be
considered intelligent or not\cite{turing1950computing}. Turing's test is based
upon whether a computer can communicate in a natural language proficiently
enough to deceive a human into thinking that the machine is also human. A
machine able to pass such a test would need to possess the ability to represent
and learn from knowledge, to be able to reason about what it knows and to be
able to process natural language\cite{russell2010artificial}. Partridge will
also need to be able to process natural language and learn from any
observations it makes. It is reasonable to consider Partridge's backend system
to be an Artificial Intelligence problem.


\subsubsection{Natural Language Processing} 

Natural Language Processing (NLP) is still a relatively unexplored discipline
and as such is a very active area of research and development within the
Artificial Intelligence community\cite{liddy2001natural}. NLP enables the
automated extraction of meaningful information from texts written in human
languages such as English or French. NLP has already been applied to many text
classification and data extraction problems. Studies have been carried out in
the detection of emotions in suicide notes\cite{citeulike:11077287}, the
classification of a web page's genre on the World Wide
Web\cite{citeulike:11288938} and emotional polarity (is the sentence positive
or negative) of a phrase or sentence\cite{Wilson05Polarity}. Liddy(2001)
defines Natural Language Processing as:

\begin{quotation} 
A theoretically motivated range of computational techniques for analyzing and
representing naturally occurring texts at one or more levels of linguistic
analysis for the purpose of achieving human-like language processing for a
range of tasks or applications \it{(Ibid)}.  
\end{quotation}

In the case of Partridge, scientific papers, constituting the naturally occuring
texts, are processed at sentence-by-sentence and word-by-word levels of
linguistics and represented in the form of Extended Markup Language (XML)
documents, a format that is both human and machine readable. This information
is then used for the purpose of classifying and searching papers in a
human-like way. 

It is therefore necessary to define what a 'human-like way' of processing
scientific papers.  Krug (2005), suggests that when browsing the internet,
humans find it much easier to locate specific information within a labelled and
logically structured document than one that is provided as a single text
entity\cite{Krug:2005:DMM:1051204}. In order to help humans to find relevant
research papers, Partridge will represent all papers in its repository in a
logical hierarchical structure. This will facilitate better information
retrieval for keyword searches and enable more advanced NLP techniques.
Partridge's document storage format should therefore be standardised to provide
a uniform way of processing each document. 

\subsubsection{CISP, CoreSC and SAPIENTA}

Soldatova and Liakata(2007) proposed a methodology for storing the Core
Information about Scientific Papers (CISP) as a way to formally represent
scientific concepts that should be present in the articles in a logical
ontology\cite{soldatova2007ontology}. They then proceed to define a schema for
their CISP ontology that defines the Core Scientific Concepts (CoreSC) as part
of the XML document itself\cite{liakata2008guidelines}. 

It is proposed that Partridge uses the CoreSC schema for document storage
to provide a standard way to access and process the papers and thus
eliminate dealing with multiple documents during its learning phase. 
Using CoreSC also offers the advantage of making Partridge compatible
with the ART corpus. This is a set of physical chemistry and biochemistry
research papers that have been pre-processed and already annotated using CISP
concepts\cite{liakataART}. This would provide Partridge with a set of papers
that could be used as a training set for classification tasks and could be used
for information retrieval tests from early on in the project.

Liakata et al. (2012) describe a system for automatically processing and
categorising sentences in a research paper according to their respective
CoreSC element\cite{citeulike:10444769}. SAPIENTA
(\url({http://www.sapientaproject.com}) was trained using the ART corpus and
can achieve promising accuracies when categorising sentences \it{(Ibid)}. With
the authors' permissions, Partridge will make use of SAPIENTA when introducing
new papers into its repository. It is hoped that preclassifying papers will
make the development of Partridge more manageable within the timeframe
available and will also allow more effort to be put into other classification
problems rather than re-implementing a SAPIENTA clone. Any modifications that
have to be made to SAPIENTA to integrate it into Partridge will be submitted
back to the original authors to help them improve their works.

After pre-processing by SAPIENTA is complete, Partridge will need to do some
classification work of its own to determine the area of study (i.e. Physics,
Chemistry, Biology), type of paper (Literature review, Case Study, Experiment)
and the polarity of the result (positive, negative, inconclusive). These tasks
involve implementing existing AI techniques and applying them specifically to
the task of text classification. To avoid the time consuming task of re-implementing these
methods, it was decided that a library should be used instead. 

\subsubsection{NLTK}

There are several existing libraries to facilitate Natural Language Processing.
Many are written for Java \cite{mallet2002}\cite{cunningham2011text} and are
very complex or not well documented. The Natural Language Toolkit (NLTK) is a
simple and intuitive library written for Python. Bird(2009) states that NLTK
was designed ``to provide an intuitive framework along with substantial
building blocks, giving users a practical knowledge of NLP". The project is
relatively mature in comparison to the above named Java libraries. There is
also a free book that accompanies the project available at
\url{http://nltk.org/book/} which provides a huge amount of information on how
to implement many popular NLP techniques using the library. For this reason
NLTK was chosen as the primary accompanying library for the project.

\subsection{Related Works}
\label{sec:prior_art}

\subsubsection{Search Engines}
There are already many existing systems for finding and filtering information
on the World Wide Web. Search engines are very useful for information retrieval
in this very large and generalised search domain. Most people have heard of
Google (\url{http://wwww.google.com}), Yahoo (\url{http://www.yahoo.co.uk}),
Bing (\url{http://www.bing.com}) and Ask (\url{http://www.ask.com}). There are
many more similar systems available for free general use across the internet.
They all present very similar user interfaces (as shown in Figure
\ref{fig:search_interfaces}) in which users are asked to supply keywords that
might be linked to relevant documents and the search engine returns a list of
Uniform Resource Locators (URLs) that they consider to match the user's query.


\begin{figure}[!ht]
        \centering
        \begin{subfigure}[b]{0.50\textwidth}
                \centering
                \includegraphics[width=\textwidth]{images/ask_front.png}
                \caption{Ask.com}
                \label{fig:ask_interface}
        \end{subfigure}%
        \begin{subfigure}[b]{0.50\textwidth}
                \centering
                \includegraphics[width=\textwidth]{images/bing_front.png}
                \caption{Bing.com}
                \label{fig:bing_interface}
        \end{subfigure}\\
        \begin{subfigure}[b]{0.50\textwidth}
                \centering
                \includegraphics[width=\textwidth]{images/google_front.png}
                \caption{Google.com}
                \label{fig:google_interface}
        \end{subfigure}%
        \begin{subfigure}[b]{0.50\textwidth}
                \centering
                \includegraphics[width=\textwidth]{images/yahoo_front.png}
                \caption{Yahoo.com}
                \label{fig:yahoo_interface}
        \end{subfigure}%
        \caption{4 popular search engine interfaces}\label{fig:animals}
        \label{fig:search_interfaces}
\end{figure}


Search engines are helpful in locating pages and websites within the World Wide
Web. Unfortunately, the problem space they deal with is usually too big for
them to find scientific papers and journals given a set of keywords. Internet
search engines index a huge proportion of irrelevant information compared to
useful information\cite{Berghel1997}, and as a result, even relatively specific
queries such as ``effects of gravity on rockets" yield millions of results (as
shown in Figure \ref{fig:rocket_results}). 

\begin{figure}[!ht]
\includegraphics[width=0.80\textwidth]{images/space_rocket_query.png}
\caption{{Google showing over 7M results for ``effects of gravity on rockets"}}
\label{fig:rocket_results}
\end{figure}

Partridge offers an advantage over these mechanisms as it will specifically
index research papers rather than attempting to index the whole Internet.
This means that there should be a higher proportion of useful information as
output compared to the output of an Internet Search Engine.

\subsubsection{Scientific Paper Search Engines}
There are also a number of search and indexing systems that specifically look
for scientific papers as opposed to web pages. One of the most publicised and
well known paper search systems is Google Scholar
(\url{http://scholar.google.com}).  As can be seen in Figure
\ref{fig:scholar_basic}, This is an adaptation of Google's general search
engine (discussed above) to specifically index and search scientific papers.
Google also offers advanced query options specific to Scholar that allow
searching by author, year and for words that occur only in the document title
as shown in figure \ref{fig:scholar_advanced}. Whilst this does deal with the
problem of `information overload' and provides even more fine control over the
information returned from searches,  the user is still required to have a very
good idea of what they are looking for in terms of keywords and/or specific
authors. It is possible that a user would not know what they are looking for
until they've seen it. Even if the user has a set of keywords to search for,
they can only search the title of the paper or the content as a whole. This
means that users who want to find a particular phrase within a CoreSC part of
the paper (e.g. only look for this phrase in the `Result' section of the
paper) are unable to get results at their desired level of detail.

\begin{figure}[!hbt]
        \centering
        \begin{subfigure}[b]{0.50\textwidth}
                \centering
                \includegraphics[width=\textwidth]{images/googlescholar_front.png}
                \caption{Google Scholar's General front page}
                \label{fig:scholar_basic}
        \end{subfigure}%
        \begin{subfigure}[b]{0.50\textwidth}
                \centering
                \includegraphics[width=\textwidth]{images/googlescholar_advanced.png}
                \caption{Advanced search features}
                \label{fig:scholar_advanced}
        \end{subfigure}

        \caption{Google Scholar's user interface}
        \label{fig:scholar_interface}
\end{figure}

Partridge will provide the option to filter papers by subject and it is hoped
that the system will also provide user-specific recommendations by profiling
them through their reading history. This will make it easier for users to find
relevant papers without knowing exactly which keywords they need to search for.
Partridge will also offer facilitate searching for keywords within a specific
CoreSC section by making use of Liakata et al's SAPIENTA project for
classifying each sentence of paper as it is added to the repository.

\subsubsection{Social Citation and Recommendation Engines}
Social citation and recommendation engines also provide a partial solution to
the `information overload' problem.  Services like Goodreads
(\url{http://www.goodreads.com/}) and CiteUlike
(\url{http://www.citeulike.org/}) allow you to register your interest in
specific authors and subjects. This allows the sites to build up a profile of
the sorts of materials that you might be interested in and provide lists of
recommendations as in Figure \cite{social_indexes}.

\begin{figure}[!hbt]
        \centering
        \begin{subfigure}[b]{0.50\textwidth}
                \centering
                \includegraphics[width=\textwidth]{images/goodreads_index.png}
                \caption{Goodreads user profile page}
                \label{fig:goodreads_index}
        \end{subfigure}%
        \begin{subfigure}[b]{0.50\textwidth}
                \centering
                \includegraphics[width=\textwidth]{images/citeulike_index.png}
                \caption{a CiteULike user profile page}
                \label{fig:citeulike_index}
        \end{subfigure}

        \caption{Goodreads and citeulike social recommendation systems}
        \label{fig:social_indexes}
\end{figure}

These systems have the ability to make recommendations to the user without
requiring specific keywords or search terms. They are able to do this by
learning the user's profile and taking into account the preferences of their
'friends' and their browsing history. However, the above-named systems do not
take into account the content of the paper or book. They only deal with
metadata as can be seen in Figure \ref{fig:social_searches}. This means that
important discriminatory information that could be contained within the actual
document content is overlooked completely. Partridge will analyse documents on
a sentence-by-sentence and possibly word-by-word basis, thereby taking account
of any embedded information that could be missed by these social metadata
systems.

\begin{figure}[!hbt]
        \centering
        \begin{subfigure}[b]{0.50\textwidth}
                \centering
                \includegraphics[width=\textwidth]{images/goodreads_search.png}
                \caption{Goodreads advanced search page}
                \label{fig:goodreads_search}
        \end{subfigure}%
        \begin{subfigure}[b]{0.50\textwidth}
                \centering
                \includegraphics[width=\textwidth]{images/citeulike_search.png}
                \caption{CiteULike advanced search options}
                \label{fig:citeulike_search}
        \end{subfigure}

        \caption{Goodreads and citeulike search only deal with metadata.}
        \label{fig:social_searches}
\end{figure}


\subsection{Methodology}

\subsection{Prototyping/Pilot Studies}

\subsection{Subsequent Changes to Methodology}

\section{Planning}

\pagebreak
\bibliographystyle{IEEEannot}
\bibliography{report}

\end{document}
