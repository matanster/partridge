%%-----------------------------------------------
%
% Include for design chapter of dissertation
%
%%----------------------------------------------



\section{ Target Platform \& High Level Considerations }

\subsection{Use Case Analysis}

Given the project objectives identified above, four primary use cases were
identified for Partridge as shown in Figure \ref{fig:use_cases}. Users can be
identified as researchers and people interested in finding and reading
scientific papers that interested them. This would involve querying the
database for relevant papers, viewing metrics on the papers that have been used
to classify them and also downloading the original paper for reading. A subset
of users were identified as authors who might be interested in adding their own
papers to the Partridge instance.

\begin{figure}[!h]
\centering
\includegraphics[width=0.4\textwidth]{images/design/use_cases.png}
\caption{Use Case Diagram for Partridge Project}
\label{fig:use_cases}
\end{figure}

\subsection{ Target Platform}

It was decided from the outset that Partridge would be a web-based tool.
Web-based systems can generally be run on any computer with access to the
internet and a modern web browser. This also means that there is no need for
the end user to install or configure extra software on their computers, making
Partridge accessible to non-technical users and those who have aggressive
software restrictions on their computers, such as GPs and users of public
computers in libraries or on academic sites.

In order to function as a website, Partridge needed to be developed as a server
application that produced Hyper Text Markup Language (HTML) output that a web
browser could interpret and display. The browser rendering the forms must then
communicate with a backend system capable of querying and returning papers to
the user based on their input. This lead to the decision to split development
of Partridge into two core components: the Web Frontend comprising of user
interface elements and presentation logic and the Web Backend comprising of
intelligent systems to classify, filter and query papers using some of the NLP
techniques discussed previously.

One of the main requirements for a web server is that it responds to requests
relatively quickly, ideally within 10 seconds or less. If they don't, the user
may get impatient and give up trying to use the system, or in some cases, their
web browser may timeout and stop trying to load the page. Many of the processes
involved in extracting meaningful CoreSC information from papers are very slow
slow. This means that processing papers during web requests is not really
feasible, since it may take several minutes for a single paper to be annotated
and classified. Therefore, a third core component was identified: a paper
preprocessor service that runs on the server and converts, annotates and
classifies papers as soon as they are uploaded.

\subsection{ Programming and Development Environment }

Rather than building a web server from the ground up, most modern web
applications are written in higher level languages that run on top of standard,
open source web servers such as Apache or nginx. Common language choices
include PHP, Python, Perl and Java, all of these languages supported by large
communities of developers and users who provide with excellent documentation
and support if required.  For the implementation of Partridge, Python was
selected as the programming language of choice. This was partially due to the
author's familiarity with the language and also due to the availability of
stable data mining\cite{curk05} and natural language
processing\cite{bird2009natural} libraries for the Python programming
environment. Python is an interpreted cross-platform language, minimising
deployment problems and supports natively compiled C and C++ extension
libraries allowing intensive processing  and number crunching to be offloaded
to native plugins, increasing application processing speed.

To further increase development speed, a Python framework for developing web
applications called \emph{Flask\cite{flask2012}} would be used to build the web
backend.

The development of the application would be carried out on a Linux desktop
computer. However, the portable nature of Python, Apache and the required
libraries meant that Partridge could theoretically be deployed to Windows and
Mac computer systems if required.

The Web Frontend for the system would need to be written using a combination of
HTML markup and JavaScript. HTML is not a programming language in itself and
doesn't contain any logic. It is merely a code representation of the interface
to be rendered in the browser window which is interpreted once it has been
downloaded from the web server. In order to carry out actions on the HTML such
as validating user input and manipulating parts of the display, JavaScript is
also downloaded from the web server and interpreted by the browser. Although
this requires the developer to have knowledge of two extra technologies on top
of Python, it also makes enforcing the design principle of keeping presentation
and logic separate a lot easier.

Due to the large number of popular web browsers on the market, implementing
JavaScript in a slightly different way, Javascript can be very difficult to
write in a cross-browser compatible way.  To maximise compatibility and reduce
development time, it was decided that libraries such as jQuery which are
designed to carry out HTML manipulation behaviours in a uniform way cross all
compatible browsers.  As of February 2013, it is estimated that Chrome and
Firefox are currently the most popular web browsers, holding 50\% and 29.6\% of
the market share respectively\cite{browserstats2013}. Internet Explorer is the
third most popular browser. However, there are several well known compatibility
issues with Internet Explorer, Microsoft themselves condemning version 6.0 of
their browser\cite{ie6death}. For this reason, it was decided that Partridge
would only support Firefox and Chrome. A working interface in modern editions
of the Internet Explorer family of browsers would be a bonus.  However, no time
was allocated to ensuring compatibility of Partridge with Internet Explorer.

\section{ System Architecture }


\begin{figure}[!ht]
\center
\includegraphics[width=0.9\textwidth]{images/design/components_high_level.png}
\caption{High Level Component Layout for Partridge}
\label{fig:high_level_components}
\end{figure}

Figure \ref{fig:high_level_components} shows a very high level description of
the system's three main components, the database server and the ways that they
communicate. Communication between the Web Interface and the other two
components is carried out via HTTP requests to the underlying Apache server.
Communication between the web backend and the paper preprocessor is implicit
via the data storage system. Direct communication between these components is
redundant since the web backend cannot gain any extra information from the
paper preprocessor while a paper is still being analysed and all finished
papers are added to the database which the web backend has full access to
anyway.


\subsection{ Preprocessor }

The preprocessor module is used to annotate and analyse new papers once they
have been uploaded by the user via the web interface. The preprocessor is
designed as a daemon which hooks into the operating system in order to monitor
a directory for new papers that have been uploaded. As new papers are detected
within the upload directory, they are placed into a process queue and the
preprocessor analyses them on a first in first out basis. When a paper is taken
from the queue, a series of processes are run upon it to prepare it for storage
in the database. These processes are illustrated in Figure
\ref{fig:flow_preprocessor}.

\begin{figure}[!h]
\centering
\includegraphics[width=0.6\textwidth]{images/design/flow_preprocessor.png}
\caption{A flowchart illustrating the preprocessor processes}
\label{fig:flow_preprocessor}
\end{figure}

\subsubsection{PDF Conversion}

The first process in the processing pipeline is conversion of the papers to a
format that can be analysed by SAPIENTA. Currently, SAPIENTA supports the
SciXML\cite{rupp2006flexible} and PubMed Central\cite{pubmedDTD} DTDs. However,
papers stored in PDF format must still be converted in order to be processed.
PDF Files will passed through a routine which extracts text from the paper and
adds the relevant XML tags to make the document SAPIENTA compatible. This
document is then passed forward to the splitter. Papers that are already in a
compatible format are passed forward without any action being taken.

\subsubsection{Sentence Splitting} 

SAPIENTA allocates each sentence within a paper a separate CoreSC label.
However, the sentence boundaries must be detected before the document is passed
into SAPIENTA for annotation. The sentence splitter uses a regular expression
to split the sentences within the document and then adds the necessary
\verb|<s>| tags to the markup to indicate the location of each sentence.

\subsubsection{SAPIENTA Annotation}

Once the paper has been split, SAPIENTA is used to annotate each sentence with
a relevant CoreSC allocation. These labels are calculated based upon the
sentence's location within the paper as well pairs and triplets of words found
consecutively within the sentence. After this stage, the paper is passed
forwards to be further classified by Partridge.


\subsubsection{Feature Extraction and Classifiers}

The final stage in the preprocessor pipeline is paper classification. During
this stage, features are extracted from the papers and used to classify the
paper in three different ways. The paper's type: case study or review paper
etc. is determined using the presence or absence of different CoreSC labels
within the paper and their relative proportions. The type of paper is
determined by the presence of domain specific nouns and adjectives within the
paper. For example, a biology paper might contain words such as enzyme or amino
acid. The result of the paper, i.e. whether the paper was conclusive and if the
results were positive or negative, are detected through the presence or absense
of words with a strong sentiment polarity as discussed by Wilson et al
(2005)\cite{Wilson05Polarity}. The results from the whole process are then
passed into the data store and saved.

\subsubsection{File Retention and Error Handling}

Each of the independent processes described above generate new files which are
temporarily stored on the server until all of the sub-processes are complete.
Once a paper analysis cycle has finished, the preprocessor triggers a cleanup
operation that removes intermediate files from the system, storing only the
initially uploaded file (which may be a PDF) and the final annotated file in a
permanent location on the filesystem.  The whole analysis process for a single
paper is also wrapped within an error handling block that automatically run the
cleanup routine if something goes wrong. This prevents the system filling up
with invalid files. This mechanism is shown in Figure
\ref{fig:preprocessor_overview}.

\begin{figure}[!h]
\vspace{5mm}
\centering
\includegraphics[width=0.6\textwidth]{images/design/paper_processor_overview.png}
\caption{Preprocessor System Overview}
\label{fig:preprocessor_overview}
\end{figure}


\subsection{ Data Storage }
It is expected that a given Partridge instance may grow in size to contain
thousands of individual papers that have been annotated and are available to
the web backend for inclusion into a user's search results. Reading in and
parsing each individual XML file stored in the system is not really feasible
when handling a HTTP request from the web frontend, this sort of process would
take a long time to execute. To provide fast search and retrieval of paper
data, a Relational Database Management server (RDBMS) was chosen for storage of
papers that have been preprocessed using the system described above. An
overview of the database schema is illustrated in Figure \ref{fig:e-r-diagram}.

\begin{figure}[th]
\vspace{5mm}
\centering
\includegraphics[width=0.8\textwidth]{images/design/e-r-diagram.png}
\caption{Entity Relationship Diagram for Partridge's RDBMS}
\label{fig:e-r-diagram}
\end{figure}

Partridge's database is required to keep track of all of the papers that have
been added to the system. The Paper entity represents a single paper stored in
Partridge. Information extracted by the classifiers such as the paper's type,
topic and result are stored as part of the main paper entity. The title and
topic are also stored for easy retrieval. One of the key requirements of
Partridge is querying within a CoreSC field of a paper. Therefore, all
sentences are stored as entities along with their CoreSC annotation. The sentence
text is an index field to facilitate fast recall from the database.

It is probable that any given author may have contributed to multiple papers
stored within the system.  Therefore authors are treated as entities within the
RDBMS and the many to many relationship between papers and authors is
facilitated using the intermediary table PaperAuthors. A PaperAuthor record
contains a boolean field used to indicate whether an author linked to a
specific paper was the primary author on that paper.

As discussed above, two or more files per paper are always stored within
partridge so that a user can retrieve them for reading. Therefore files are
kept in their own table along with a record of their type (eg. XML or PDF). 

\subsection{ Web Backend }

Partridge's web backend component is used to initially serve the HTML and
JavaScript used to represent the User interface and to communicate with the
JavaScript frontend running inside the browser via HTTP requests. It is used to
interpret HTTP request fields into SQL queries and mediate queries made to the
RDBMS on behalf of the user. An example use of the backend system can be seen
in Figure \ref{fig:backend_sequence}.

\begin{figure}[!ht]
\centering
\includegraphics[width=0.75\textwidth]{images/design/backend_sequence.png}
\caption{Sequence Diagram for a Query in Partridge}
\label{fig:backend_sequence}
\end{figure}

The Flask web framework uses a model view controller-like architecture. Each
behaviour of the server: handling paper uploads, displaying paper query
results, allowing users to download papers, can be considered a `view'. Views
register themselves with Flask under a specific URL. When flask receives a
request to any such URL, it automatically routes the request through to the
View object\cite{flask2012}.

\subsubsection{Query View Backend}
The query view is has two key responsibilities. The first is to display the
query form to the user. This is a simple matter of sending an HTML file stored
on the server to the browser that made the request. 

The key responsibility of the query view is to translate incoming HTTP requests
into search queries, retrieve a set of papers from the RDBMS  and return human
readable results to the user. One of the most important steps in this process
is to cleanse the incoming data and prevent SQL injection attacks that
unscrupulous users may attempt to use to damage or purge the Partridge
database. The system must also be capable of interpreting data retrieved from
the database into HTML to be returned to the user's browser. The server
mechanism utilises Flask's built in templating mechanism in order to quickly
transform Python-specific data structures into valid HTML markup and return it
to the user\cite{flask2012}.

\subsubsection{Paper Upload View Backend}

The paper upload view backend is responsible for handling file uploads from the
HTML form and ensuring that files are placed in the right place so that the
preprocessor can find them. The main challenge for this submodule is storing
the file using a unique name so that different users uploading files don't
overwrite each other's data. This is handled through the use of the Python UUID
module which generates universally unique 128-bit identifiers as detailed in RFC
4122\cite{rfc4122}. The low rate of collisions between UUID values should
insure that the chances of two paper filenames colliding is very low. 

The view also carries out validation on the filename to ensure that it is an
XML or PDF file. No further validation is carried out by this system since the
paper processor carries out file contents inspection and removes invalid file
types automatically.


\subsection{ Web Frontend }

The web frontend consists of sets of HTML and JavaScript interfaces that are
equipped to communicate with their relevant backend system using

\subsubsection{ Query Form }

\subsubsection{ Results Page }

\subsubsection{ Paper Profile Page }

\subsubsection{Paper Upload Form}
Paper uploading is a 
